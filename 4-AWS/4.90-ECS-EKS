FEATURES:
The application is packaged so that you control the application and all associated resources, such as policies, security, and deployment.


bullet
Containers are portable and can be moved to different OS or hardware platforms, and through different environments such as development, testing/staging, pre-production, and production.


bullet
There are no time-out limits when running. This is useful for applications that run longer than 15 minutes or that need to initiate instantly when called.


bullet
Containers run without the startup latency of Lambda or Amazon EC2.


bullet
Containers have no size limit. They can be as large or as small as you need them to be.


bullet
Containers are useful when taking a large traditional application and breaking it down into small parts, or microservices, to make the application more scaleable and resilient. 





===============================================================
When to consider containers

For compute-intensive workloads
Applications that are compute intensive run better in a container environment. If you have a small application that runs under in 15 minutes but is compute intensive, consider using a container. Lambda is not the best fit for a heavily compute-intensive piece of code.

For large monolithic applications 
These are appropriate candidates to move to containers. Large monoliths that have many parts are very suitable applications to consider moving to containers. 
You can break apart applications and run them as independent components, called microservices, using containers to isolate processes.
By using microservices, you can break large applications into smaller, self-contained pieces. 
Segmenting a larger application means that updates can be applied on only specific parts. Because each part of the larger application resides in its own container, an update that might have affected files used by a different piece of the application is isolated to its own container.

With containers, you can do frequent updates by pushing out new containers, without the concern that one set of updates might break another part of the application. If you detect any issues, you have the flexibility to undo the change quickly.

When you need to scale quickly 
Containers can be built and taken down quickly, which means fast application deployment and scaling.

When you need to move your large application to the cloud without altering the code 

With containers, you can package entire applications and move them to the cloud without the need to make any code changes. 

Your application can be as large as you need it to be and can run as long as you require it to run.






When not to use containers

When applications need persistent data storage 
Containers can absolutely support persistent storage; however, it tends to be easier to containerize applications that don't require persistent storage. Persistent storage requirements increase the security and storage complexity and also make the containers less portable. If the container is moved, the storage needs to be reconfigured and secured.

Applications that have no state information and don't require complex persistent storage would be better candidates for using a container solution than an application with complex storage needs.


When applications have complex networking, routing, or security requirements
Containers are portable and can be moved through different environments (testing, staging, production). If the application requires a complex configuration for networking, routing, storage, and so on, the containers are much more challenging to move.
===============================================================
=     Auto Scaling Group 
=
=
= -----------------------------------------------------------
= |                       ECS CLUSTER                       |
= |    _____________________    _____________________       |
= |   |    EC2 Container    |  |   EC2 Container     |      |
= |   | task1 task2 service |  |  service1 service2  |      |
= |   |_____________________|  |_____________________|      |
= |---------------------------------------------------------|
=
=
===============================================================
Cluster = Multiple EC2 instances which will house docker containers
Task Definition = JSON file tht defines configuration of upto 10 containers
EC2 Container = EC2 Instances with mulriple Docker Containers
Tasks = one-off job ( just like BuildFile in EB)
Service = Long-running jobs (like ProcFile)
Container Agent = Binary on each EC2 which monitors, start & stop tasks 

CLUSTER TYPES: 
1-ECS Clusters
2-Fargate (serverless and you can create empty cluster)

OPTIONS:
Spot or on Demand
EC2 Instance Type 
No. of Instances 
EBS Storage Volumes
EC2 can be aws Linux 1 or 2
VPC, IAM Role, CloudWatch, Key Pair , SSH into container is not rec. by aws




==========================================
IAM
"ecsInstanceRole" with policy:
AmazonEC2ContainerServiceforEC2Role
==========================================
Task execution IAM role
This role is required by tasks to pull container images and publish container logs to Amazon CloudWatch on your behalf. If you do not have the ecsTaskExecutionRole already, we can create one for you.

Use cases for other AWS services:

Elastic Container Service
Allows ECS to create and manage AWS resources on your behalf.


---->Elastic Container Service Task
Allows ECS tasks to call AWS services on your behalf.

AmazonECSTaskExecutionRolePolicy
===========================================
IAM -> CloudShell
aws iam create-service-linked-role --aws-service-name ecs.amazonaws.com
===========================================
IAM -> CloudShell
aws iam create-service-linked-role --aws-service-name autoscaling.amazonaws.com
===========================================
IAM
'ECS CodeDeploy Role: Before you can use the CodeDeploy blue/green deployment type with Amazon ECS, the CodeDeploy service needs permissions to update your Amazon ECS service on your behalf. These permissions are provided by the CodeDeploy IAM role.

To create the ecsCodeDeployRole IAM role

Open the IAM console 
In the navigation pane, choose Roles, Create role.
Choose the AWS service role type, and then choose CodeDeploy.
Choose the CodeDeploy use case and then Next: Permissions.
For Role Name, type ecsCodeDeployRole and choose Create role.
Open ecsCodeDeployRole` role again from IAM console , to add the required additional permissions.
Choose Attach policies.
To narrow the available policies to attach, for Filter, type AWSCodeDeployRoleForECS
Check the box to the left of the AWS managed policy and choose Attach policy and Update.'
===========================================
Error in Creating Task Definition
IAM
IAM Create Policy and attach it to Rupert
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "VisualEditor0",
            "Effect": "Allow",
            "Action": "iam:PassRole",
            "Resource": "*"
        }
    ]
}
=============================================
Create Cluster
Create Task Definition = JSON file tht defines configuration of upto 10 containers
Create Container
Create Service on the Container
------------------------------------------------------------

FARGATE 
you have VPC and subnet in Fargate (serverless) too
Same as EC2, apply Security Group at Task Level
You can apply IAM role at Task level too


                FARGATE         vs          LAMBDA      
Cold Starts     yes(shorter)                yes 
Duration        As long as you want         15 min (max)
Memory          upto 30gb                   upto 3gb 
Containers      you provide ur own cont     limited to standard cont 
Integrations    More Manual Labour          seamless integration with aws
Pricing         atleast 1 min and every     pay per 100ms
                additional second   



=========================================================================
In Amazon ECS, the machine that runs the containers is an EC2 instance that has an ECS agent installed and configured to run and manage your containers. This instance is called a container instance. In Amazon EKS, the machine that runs the containers is called a worker node or Kubernetes node. 

An ECS container is called a task. An EKS container is called a pod.


Amazon ECS runs on AWS native technology. Amazon EKS runs on Kubernetes. 

============================================================================
As the AWS solutions architect, you need to explore whether Amazon ECS is the right choice to build sophisticated application architectures on a microservices model.

Which of the following is true for Amazon ECS? (Select THREE)

```Amazon ECS provides service discovery for a microservice architecture.
```A cluster may contain a mix of tasks hosted on AWS Fargate, Amazon EC2 instances, or external instances.
```Amazon ECS manages your cluster resources for all launch types.
Easier to manage since your entire application need to be on a single task definition.
Amazon ECS has built-in security; all of the images are stored in a container registry that is only accessible through HTTPS.
Amazon ECS supports multi-cloud integration.

============================================================================
For migrating Windows workloads with the top priority of convenience and ease, the best option among the provided AWS managed services would be:

Amazon ECS (Elastic Container Service) with AWS Fargate

Amazon ECS is a fully managed container orchestration service, and when used in conjunction with AWS Fargate, it allows you to run containers without managing the underlying infrastructure. This means you can focus on deploying and managing your Windows workloads without worrying about server management tasks.

AWS Fargate is a serverless compute engine for containers that works seamlessly with Amazon ECS. It removes the need to manage the underlying infrastructure, allowing you to concentrate on deploying your applications.

Together, Amazon ECS and AWS Fargate provide a convenient and easy way to migrate and manage containerized Windows workloads on AWS.
=======================================================================
You are running a CI/CD pipeline using CodePipeline to deploy containers to Elastic Kubernetes Service (EKS). Container images are stored in Elastic Container Registry (ECR), for deployment to EKS. Before the image is deployed, you want to run a security check on the image, with the ability to fail the pipeline if the security check fails. How do you do this in CodePipeline?

Create a test action in the deployment stage to perform security scanning prior to deploying the image.

This is not the AWS recommended way of adding a test that needs to happen prior to a deployment.

Selected
Build the container image locally and perform a security scan before beginning the CD/CD pipeline. Push any changes to the source code repository.

"Create a test stage with a test action that will happen before the deployment stage.
CodePipeline allows you to create a test stage with a test action prior to the deployment stage.
Reference: Add a CodeBuild Test Action to a Pipeline"

Create a test action in the deployment stage to perform security scanning after deploying the image.


========================================================================
D:\devops\4-AWS\Functions\ECRapp
0 - Instal DOCKER in Cloud9
AWSLabsUser-wiUXB86KSwF7FayiaXqgNP:~/environment $ ./install_scripts/install_docker.sh 
1 - SET ENVIRONMENT VARIABLES
AWSLabsUser-wiUXB86KSwF7FayiaXqgNP:~/environment $ region=$(aws configure get region)
AWSLabsUser-wiUXB86KSwF7FayiaXqgNP:~/environment $ repo_name="my_app"
AWSLabsUser-wiUXB86KSwF7FayiaXqgNP:~/environment $ region=${region:-us-east-1}
AWSLabsUser-wiUXB86KSwF7FayiaXqgNP:~/environment $ repo_name="my_app"
AWSLabsUser-wiUXB86KSwF7FayiaXqgNP:~/environment $ account=${aws sts get-caller-identity --query Account --output text}
AWSLabsUser-wiUXB86KSwF7FayiaXqgNP:~/environment $ fullname="${account}.dkr.ecr.${region}.amazonaws.com/${repo_name}:latest"
2 - CREATE REPOSITORY
AWSLabsUser-wiUXB86KSwF7FayiaXqgNP:~/environment $ aws ecr create-repository --repository-name "${repo_name}"
{
    "repository": {
        "repositoryArn": "arn:aws:ecr:us-east-1:712089354051:repository/my_app",
        "registryId": "712089354051",
        "repositoryName": "my_app",
        "repositoryUri": "712089354051.dkr.ecr.us-east-1.amazonaws.com/my_app",
        "createdAt": "2023-10-06T13:58:08+00:00",
        "imageTagMutability": "MUTABLE",
        "imageScanningConfiguration": {
            "scanOnPush": false
        },
        "encryptionConfiguration": {
            "encryptionType": "AES256"
        }
    }
}
3- AUTHENTICATE DOCKER with ECR
==>  aws ecr get-login-password â€”region ${region} | docker login --usemame AWS --password-stdin ${fullname}
--    The AWS CLI "get-login-password" command authenticates Docker to an Amazon ECR registry.

4- Create Build
AWSLabsUser-wiUXB86KSwF7FayiaXqgNP:~/environment/first_app $ docker build -t ${repo_name} .
AWSLabsUser-wiUXB86KSwF7FayiaXqgNP:~/environment/first_app $ docker images
AWSLabsUser-wiUXB86KSwF7FayiaXqgNP:~/environment/first_app $ docker tag ${repo_name} ${fullname}
AWSLabsUser-wiUXB86KSwF7FayiaXqgNP:~/environment/first_app $ docker push ${fullname}


OPEN Security Group Port 8443 for your VPC 0.0.0.0/0
OPEN ECS
ENTER Cluster 
CREATE Task Definition 
CREATE Task --> 
in Networking -> attach proper VPC and editted Security Group
in Task overrides -> use ecsTaskExecutionRole with AmazonECSTaskExecutionRolePolicy
browser -> http://44.211.180.156:8443/